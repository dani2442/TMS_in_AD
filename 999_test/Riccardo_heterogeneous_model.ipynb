{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the packages needed for analyses\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from numba import jit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up Hopf as our model \n",
    "import WholeBrain.Models.supHopf as Hopf\n",
    "from WholeBrain.simulate_SimOnly import Tmaxneuronal\n",
    "Hopf.initialValue = 0.1\n",
    "neuronalModel = Hopf\n",
    "\n",
    "# Set up our integrator\n",
    "import WholeBrain.Integrator_EulerMaruyama as myIntegrator\n",
    "integrator = myIntegrator\n",
    "integrator.neuronalModel = neuronalModel\n",
    "integrator.verbose = False\n",
    "integrator.clamping = False\n",
    "\n",
    "# Set up the integration parameters\n",
    "dt = 5e-5\n",
    "# tmax is equal to the number of timepoints: 193\n",
    "tmax= 193\n",
    "ds = 1e-4\n",
    "Tmaxneuronal = int((tmax+dt))\n",
    "\n",
    "import WholeBrain.simulate_SimOnly as simulateBOLD\n",
    "simulateBOLD.warmUp = True\n",
    "simulateBOLD.integrator = integrator\n",
    "simulateBOLD.warmUpFactor = 606./2000.\n",
    "\n",
    "# Set up the code to obtain the variables we want to maximize similarity to empirical FC\n",
    "import WholeBrain.Observables.FC as FC\n",
    "#import WholeBrain.Observables.swFCD as swFCD\n",
    "import WholeBrain.Observables.phFCD as phFCD\n",
    "import WholeBrain.Optimizers.ParmSeep as ParmSeep\n",
    "ParmSeep.simulateBOLD = simulateBOLD\n",
    "ParmSeep.integrator = integrator\n",
    "ParmSeep.verbose = True\n",
    "\n",
    "# set BOLD filter settings\n",
    "import WholeBrain.Utils.filteredPowerSpectralDensity as filtPowSpectr\n",
    "import WholeBrain.BOLDFilters as BOLDfilters\n",
    "\n",
    "# These filters are applied in the filtPowSpectr function that we use to extract the intrinsic frequencies of each region.\n",
    "# They are also applied to process the FC and swFCD and phFCD, but you can set the corresponding parameter to False later on. 0.04-0.07 Hz common to extract intrinsic frequencies\n",
    "BOLDfilters.flp = 0.04\n",
    "BOLDfilters.fhi = 0.07\n",
    "BOLDfilters.TR = 3.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCnorm.shape=(78, 78)\n",
      "filtPowSpetraMultipleSubjects: subject 0 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 1 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 2 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 3 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 4 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 5 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 6 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 7 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 8 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 9 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 10 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 11 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 12 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 13 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 14 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 15 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 16 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 17 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 18 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 19 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 20 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 21 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 22 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 23 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 24 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 25 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 26 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 27 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 28 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 29 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 30 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 31 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 32 (of 33)\n",
      "ADHopf Setup done!\n"
     ]
    }
   ],
   "source": [
    "# Get the list of names of all regions in the AAL atlas. This is needed to get the right indices, to then filter the FC\n",
    "import csv\n",
    "# This is a sublist of labels of the cortical regions that were included in the paper by Demirtas et al. - AAL atlas (78 regions, excluding infratentorial and deep)\n",
    "with open ('/home/riccardo/ADNI_Hopf/Utils/aal_regions_included.csv', newline='') as f:\n",
    "    new_reader = csv.reader(f)\n",
    "    included_regions = list(new_reader)\n",
    "f.close()\n",
    "\n",
    "# Get the AAL atlas labels\n",
    "import nilearn.datasets as datasets\n",
    "aal = datasets.fetch_atlas_aal()\n",
    "labels = np.array(aal.labels)\n",
    "# create an array with the indices of each label (note that these are not the label number from the nifti image)\n",
    "indices = np.array([i for i in enumerate(labels)])\n",
    "SC_regions_index = np.isin(labels, included_regions)\n",
    "# filter the indices that we want based on the position so to have a final SC matrix only for the regions we considered.\n",
    "SC_78_regions_aal_atlas = indices[SC_regions_index]\n",
    "filter_SC = np.array([int(i) for i in SC_78_regions_aal_atlas[:,0]])\n",
    "\n",
    "# Set file path for SC matrix\n",
    "x_path = '/home/riccardo/ADNI_Hopf/Utils/'\n",
    "# Load structural connectivity matrix and use it as parameter in Hopf model\n",
    "xfile = 'SCmatrices88healthy.mat' \n",
    "M = sio.loadmat(x_path + xfile); \n",
    "mat = M['SCmatrices']\n",
    "# averaging the SC among subjects\n",
    "mat0 = np.mean(mat,axis = 0)\n",
    "# Filter the SC to have just the 78 regions we considered\n",
    "x_mat0 = mat0[filter_SC]\n",
    "new_mat0 = x_mat0.T[filter_SC]\n",
    "# Prevent full synchronization of the model\n",
    "SCnorm = new_mat0 * 0.2 / new_mat0.max() \n",
    "np.fill_diagonal(SCnorm,0)\n",
    "print('SCnorm.shape={}'.format(new_mat0.shape))    \n",
    "Hopf.setParms({'SC':SCnorm})\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Retrieve the data for all subjects \n",
    "# ------------------------------------------------\n",
    "timeseries = np.load('/home/riccardo/ADNI_Hopf/Results/timeseries_all.npy')\n",
    "nsubjects, nNodes, Tmax = timeseries.shape\n",
    "all_fMRI = {s: d for s,d in enumerate(timeseries)} \n",
    "# Since we aleardy filtered the data in the previous step from Nilearn, we aren't going to filter them again. Otherwise, a possible alternative, could be to add another\n",
    "# BOLDfilters to actually re-set the filters after the f_diff was extracted and before the call to the simulation.\n",
    "distanceSettings = {'FC': (FC, False), 'phFCD': (phFCD, True)}\n",
    "\n",
    "simulateBOLD.TR = 3.  # Recording interval: 1 sample every 3 seconds\n",
    "simulateBOLD.dt = 0.1 * simulateBOLD.TR / 2.\n",
    "simulateBOLD.Tmax = Tmax  # This is the length, in seconds\n",
    "simulateBOLD.dtt = simulateBOLD.TR  # We are not using milliseconds\n",
    "simulateBOLD.t_min = 10 * simulateBOLD.TR\n",
    "# simulateBOLD.recomputeTmaxneuronal() <- do not update Tmaxneuronal this way!\n",
    "# simulateBOLD.warmUpFactor = 6.\n",
    "simulateBOLD.Tmaxneuronal = (Tmax-1) * simulateBOLD.TR + 30\n",
    "integrator.ds = simulateBOLD.TR  # record every TR millisecond\n",
    "\n",
    "# Hopf.beta = 0.01\n",
    "f_diff = filtPowSpectr.filtPowSpetraMultipleSubjects(timeseries, TR=3.)  # should be baseline_group_ts .. or baseling_group[0].reshape((1,52,193))\n",
    "f_diff[np.where(f_diff == 0)] = np.mean(f_diff[np.where(f_diff != 0)])  # f_diff(find(f_diff==0))=mean(f_diff(find(f_diff~=0)))\n",
    "\n",
    "Hopf.omega = 2 * np.pi * f_diff\n",
    "\n",
    "print(\"ADHopf Setup done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_a_value = -0.02\n",
    "warmUp = True\n",
    "warmUpFactor = 10.\n",
    "\n",
    "def computeSubjectSimulation():\n",
    "    # integrator.neuronalModel.SC = C\n",
    "    # integrator.initBookkeeping(N, Tmaxneuronal)\n",
    "    if warmUp:\n",
    "        currObsVars = integrator.warmUpAndSimulate(dt, Tmaxneuronal, TWarmUp=Tmaxneuronal/warmUpFactor)\n",
    "    else:\n",
    "        currObsVars = integrator.simulate(dt, Tmaxneuronal)\n",
    "    # currObsVars = integrator.returnBookkeeping()  # curr_xn, curr_rn\n",
    "    neuro_act = currObsVars[:,1,:]  # curr_rn\n",
    "    return neuro_act\n",
    "    \n",
    "\n",
    "def loadXBurden(condition):\n",
    "    # ------------------- load and stack the different wm burdens\n",
    "    wm_hc = np.load('/home/riccardo/ADNI_Hopf/Results/wmh_volumes_HC.npy')\n",
    "    wm_mci = np.load('/home/riccardo/ADNI_Hopf/Results/wmh_volumes_MCI.npy')\n",
    "    wm_overall = np.load('/home/riccardo/ADNI_Hopf/Results/wmh_volumes_ALL.npy')\n",
    "    # ------------------- load the specific subject wm\n",
    "    if condition == 'hc':\n",
    "        wmBurden = wm_hc\n",
    "    elif condition == 'mci':\n",
    "        wmBurden = wm_mci\n",
    "    elif condition == 'all':\n",
    "        wmBurden = wm_overall\n",
    "    # ------------------- normalize and return\n",
    "    # wmBurdenNorm = (wmBurden - np.min(wmBurden))/np.ptp(wmBurden)  # Normalize each individual in [0,1]\n",
    "    wmBurdenNorm = (wmBurden - np.min(wm_overall))/np.ptp(wm_overall)  # Normalize the whole group in [0,1]\n",
    "    return wmBurdenNorm\n",
    "\n",
    "# ------------ load wm burden\n",
    "conditionToStudy='all' #lower case, can be hc or mci or all\n",
    "wmBurden = loadXBurden(conditionToStudy)\n",
    "mode = 'homogeneous'  # homogeneous/heterogeneous\n",
    "\n",
    "# Note that this homogeneous is intended as homogeneous inside the same patient, so all regions of one patient have the same wmBurden, but different patients have different wmBurdens.\n",
    "# Heterogenous, instead, means that different regions in the same patient have different wmBurdens\n",
    "if mode == 'homogeneous':\n",
    "    #avgwm = np.average(wmBurden)\n",
    "    wmBurden = np.array([np.ones([nNodes]) * wmBurden[i] for i in range(len(wmBurden))])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outFilePath = '/home/riccardo/ADNI_Hopf/Results/G_fitted_to_HC-minimalWMH/heterogeneous_model_across_subject_homogeneous_regional_WMH_weight'\n",
    "\n",
    "def fittingPipeline_homogeneous(subj_fMRI,\n",
    "                    distanceSettings,  # This is a dictionary of {name: (distance module, apply filters bool)}\n",
    "                    wms, wmBurden, subjectName):\n",
    "    print(\"\\n\\n###################################################################\")\n",
    "    print(\"# Fitting with ParmSeep\")\n",
    "    print(\"###################################################################\\n\")\n",
    "    # Now, optimize all we (G) values: determine optimal G to work with\n",
    "    wmParms = [{'a': base_a_value + (wmW * wmBurden)} for wmW in wmWs]\n",
    "    fitting = ParmSeep.distanceForAll_Parms(subj_fMRI,\n",
    "                                            wmWs, \n",
    "                                            wmParms,\n",
    "                                            NumSimSubjects=1,\n",
    "                                            distanceSettings=distanceSettings,\n",
    "                                            parmLabel='a_heterogeneous_between_subjects_current_wmW_',\n",
    "                                            fileNameSuffix='_'+subjectName,\n",
    "                                            outFilePath=outFilePath)\n",
    "\n",
    "    optimal = {sd: distanceSettings[sd][0].findMinMax(fitting[sd]) for sd in distanceSettings}\n",
    "    return optimal, fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_list = np.load('/home/riccardo/ADNI_Hopf/Results/subject_list_timeseries_all.npy')\n",
    "\n",
    "subjectName = ''\n",
    "warmUp = True\n",
    "warmUpFactor = 10.\n",
    "Hopf.setParms({'we': 2.9})\n",
    "wmWs = np.round(np.arange(-0.1,0.1,0.005), 4)\n",
    "\n",
    "\n",
    "def fittingPipeline_heterogeneous(all_fMRI, wmBurden, wmWs):\n",
    "    best_parameters_dict = {}\n",
    "    for k, subjectName in enumerate(subj_list):\n",
    "        subj_fMRI = {k:all_fMRI[k]}\n",
    "        wmBurden_subj = wmBurden[k]\n",
    "        best_parameters = fittingPipeline_homogeneous(subj_fMRI=subj_fMRI, distanceSettings=distanceSettings, subjectName=subjectName, wms=wmWs, wmBurden = wmBurden_subj)\n",
    "        best_parameters_dict[subjectName] = best_parameters\n",
    "    return best_parameters_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the memory load the simulations cannot be run all in the same batch, at least not in Jupyter for VSCode where I am working at the moment on my personal laptop. Luckily the code can be run in batches, this means that we can subdivide the whole simulation into 3 separate batches and run it 3 times. Each time you have to close down the notebook and reopen it. After the simulation is run and the files are saved for all patients we can just re-run the functions altogether and this will just load the already computed simulations. Also this crashes VSCode ( [it is a known bug](https://github.com/microsoft/vscode/issues/155242)), but we are still able to run the code, just we won't see any output on the screen, but we can save a combined dictionary as a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fittingPipeline_heterogeneous' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 29\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# def fittingPipeline_heterogeneous_first(all_fMRI, wmBurden, wmWs):\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#     best_parameters_dict = {}\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m#     for k, subjectName in enumerate(subj_list[:11]):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39m#         best_parameters_dict[subjectName] = best_parameters\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39m#     return best_parameters_dict\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m best_parms_dict_first_batch \u001b[39m=\u001b[39m fittingPipeline_heterogeneous(all_fMRI\u001b[39m=\u001b[39mall_fMRI, wmBurden\u001b[39m=\u001b[39mwmBurden, wmWs\u001b[39m=\u001b[39mwmWs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fittingPipeline_heterogeneous' is not defined"
     ]
    }
   ],
   "source": [
    "# def fittingPipeline_heterogeneous_first(all_fMRI, wmBurden, wmWs):\n",
    "#     best_parameters_dict = {}\n",
    "#     for k, subjectName in enumerate(subj_list[:11]):\n",
    "#         subj_fMRI = {k:all_fMRI[k]}\n",
    "#         wmBurden_subj = wmBurden[k]\n",
    "#         best_parameters = fittingPipeline_homogeneous(subj_fMRI=subj_fMRI, distanceSettings=distanceSettings, subjectName=subjectName, wms=wmWs, wmBurden = wmBurden_subj)\n",
    "#         best_parameters_dict[subjectName] = best_parameters\n",
    "#     return best_parameters_dict\n",
    "\n",
    "# def fittingPipeline_heterogeneous_first(all_fMRI, wmBurden, wmWs):\n",
    "#     best_parameters_dict = {}\n",
    "#     for k, subjectName in enumerate(subj_list[11:22]):\n",
    "#         subj_fMRI = {k:all_fMRI[k]}\n",
    "#         wmBurden_subj = wmBurden[k]\n",
    "#         best_parameters = fittingPipeline_homogeneous(subj_fMRI=subj_fMRI, distanceSettings=distanceSettings, subjectName=subjectName, wms=wmWs, wmBurden = wmBurden_subj)\n",
    "#         best_parameters_dict[subjectName] = best_parameters\n",
    "#     return best_parameters_dict\n",
    "\n",
    "\n",
    "# def fittingPipeline_heterogeneous_first(all_fMRI, wmBurden, wmWs):\n",
    "#     best_parameters_dict = {}\n",
    "#     for k, subjectName in enumerate(subj_list[22:]):\n",
    "#         subj_fMRI = {k:all_fMRI[k]}\n",
    "#         wmBurden_subj = wmBurden[k]\n",
    "#         best_parameters = fittingPipeline_homogeneous(subj_fMRI=subj_fMRI, distanceSettings=distanceSettings, subjectName=subjectName, wms=wmWs, wmBurden = wmBurden_subj)\n",
    "#         best_parameters_dict[subjectName] = best_parameters\n",
    "#     return best_parameters_dict\n",
    "\n",
    "best_parms_dict_first_batch = fittingPipeline_heterogeneous(all_fMRI=all_fMRI, wmBurden=wmBurden, wmWs=wmWs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# open file for writing, \"w\" \n",
    "f = open(\"/home/riccardo/ADNI_Hopf/Results/G_fitted_to_HC-minimalWMH/heterogeneous_model_best_parameters_dictionary.pkl\",\"wb\")\n",
    "\n",
    "# write json object to file\n",
    "pickle.dump(best_parms_dict, f)\n",
    "\n",
    "# close file\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('neurolib': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18e43de8b878494df763bc7045d8b6860d297bafdd730193e66e4d65bb98bce4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
