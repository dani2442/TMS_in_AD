{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCnorm.shape=(78, 78)\n",
      "filtPowSpetraMultipleSubjects: subject 0 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 1 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 2 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 3 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 4 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 5 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 6 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 7 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 8 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 9 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 10 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 11 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 12 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 13 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 14 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 15 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 16 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 17 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 18 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 19 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 20 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 21 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 22 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 23 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 24 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 25 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 26 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 27 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 28 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 29 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 30 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 31 (of 33)\n",
      "filtPowSpetraMultipleSubjects: subject 32 (of 33)\n",
      "ADHopf Setup done!\n"
     ]
    }
   ],
   "source": [
    "# Load all the packages needed for analyses\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from numba import jit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up Hopf as our model \n",
    "import WholeBrain.Models.supHopf as Hopf\n",
    "from WholeBrain.simulate_SimOnly import Tmaxneuronal\n",
    "Hopf.initialValue = 0.1\n",
    "neuronalModel = Hopf\n",
    "\n",
    "# Set up our integrator\n",
    "import WholeBrain.Integrator_EulerMaruyama as myIntegrator\n",
    "integrator = myIntegrator\n",
    "integrator.neuronalModel = neuronalModel\n",
    "integrator.verbose = False\n",
    "integrator.clamping = False\n",
    "\n",
    "# Set up the integration parameters\n",
    "dt = 5e-5\n",
    "# tmax is equal to the number of timepoints: 193\n",
    "tmax= 193\n",
    "ds = 1e-4\n",
    "Tmaxneuronal = int((tmax+dt))\n",
    "\n",
    "import WholeBrain.simulate_SimOnly as simulateBOLD\n",
    "simulateBOLD.warmUp = True\n",
    "simulateBOLD.integrator = integrator\n",
    "simulateBOLD.warmUpFactor = 606./2000.\n",
    "\n",
    "# Set up the code to obtain the variables we want to maximize similarity to empirical FC\n",
    "import WholeBrain.Observables.FC as FC\n",
    "#import WholeBrain.Observables.swFCD as swFCD\n",
    "import WholeBrain.Observables.phFCD as phFCD\n",
    "import WholeBrain.Optimizers.ParmSeep as ParmSeep\n",
    "ParmSeep.simulateBOLD = simulateBOLD\n",
    "ParmSeep.integrator = integrator\n",
    "ParmSeep.verbose = True\n",
    "\n",
    "# set BOLD filter settings\n",
    "import WholeBrain.Utils.filteredPowerSpectralDensity as filtPowSpectr\n",
    "import WholeBrain.BOLDFilters as BOLDfilters\n",
    "\n",
    "# These filters are applied in the filtPowSpectr function that we use to extract the intrinsic frequencies of each region.\n",
    "# They are also applied to process the FC and swFCD and phFCD, but you can set the corresponding parameter to False later on. 0.04-0.07 Hz common to extract intrinsic frequencies\n",
    "BOLDfilters.flp = 0.04\n",
    "BOLDfilters.fhi = 0.07\n",
    "BOLDfilters.TR = 3.0\n",
    "\n",
    "\n",
    "# Get the list of names of all regions in the AAL atlas. This is needed to get the right indices, to then filter the FC\n",
    "import csv\n",
    "# This is a sublist of labels of the cortical regions that were included in the paper by Demirtas et al. - AAL atlas (78 regions, excluding infratentorial and deep)\n",
    "with open ('/home/riccardo/ADNI_Hopf/Utils/aal_regions_included.csv', newline='') as f:\n",
    "    new_reader = csv.reader(f)\n",
    "    included_regions = list(new_reader)\n",
    "f.close()\n",
    "\n",
    "# Get the AAL atlas labels\n",
    "import nilearn.datasets as datasets\n",
    "aal = datasets.fetch_atlas_aal()\n",
    "labels = np.array(aal.labels)\n",
    "# create an array with the indices of each label (note that these are not the label number from the nifti image)\n",
    "indices = np.array([i for i in enumerate(labels)])\n",
    "SC_regions_index = np.isin(labels, included_regions)\n",
    "# filter the indices that we want based on the position so to have a final SC matrix only for the regions we considered.\n",
    "SC_78_regions_aal_atlas = indices[SC_regions_index]\n",
    "filter_SC = np.array([int(i) for i in SC_78_regions_aal_atlas[:,0]])\n",
    "\n",
    "# Set file path for SC matrix\n",
    "x_path = '/home/riccardo/ADNI_Hopf/Utils/'\n",
    "# Load structural connectivity matrix and use it as parameter in Hopf model\n",
    "xfile = 'SCmatrices88healthy.mat' \n",
    "M = sio.loadmat(x_path + xfile); \n",
    "mat = M['SCmatrices']\n",
    "# averaging the SC among subjects\n",
    "mat0 = np.mean(mat,axis = 0)\n",
    "# Filter the SC to have just the 78 regions we considered\n",
    "x_mat0 = mat0[filter_SC]\n",
    "new_mat0 = x_mat0.T[filter_SC]\n",
    "# Prevent full synchronization of the model\n",
    "SCnorm = new_mat0 * 0.2 / new_mat0.max() \n",
    "np.fill_diagonal(SCnorm,0)\n",
    "print('SCnorm.shape={}'.format(new_mat0.shape))    \n",
    "Hopf.setParms({'SC':SCnorm})\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Retrieve the data for all subjects \n",
    "# ------------------------------------------------\n",
    "timeseries = np.load('/home/riccardo/ADNI_Hopf/Results/timeseries_all.npy')\n",
    "nsubjects, nNodes, Tmax = timeseries.shape\n",
    "all_fMRI = {s: d for s,d in enumerate(timeseries)} \n",
    "# Since we aleardy filtered the data in the previous step from Nilearn, we aren't going to filter them again. Otherwise, a possible alternative, could be to add another\n",
    "# BOLDfilters to actually re-set the filters after the f_diff was extracted and before the call to the simulation.\n",
    "distanceSettings = {'FC': (FC, False), 'phFCD': (phFCD, True)}\n",
    "\n",
    "simulateBOLD.TR = 3.  # Recording interval: 1 sample every 3 seconds\n",
    "simulateBOLD.dt = 0.1 * simulateBOLD.TR / 2.\n",
    "simulateBOLD.Tmax = Tmax  # This is the length, in seconds\n",
    "simulateBOLD.dtt = simulateBOLD.TR  # We are not using milliseconds\n",
    "simulateBOLD.t_min = 10 * simulateBOLD.TR\n",
    "# simulateBOLD.recomputeTmaxneuronal() <- do not update Tmaxneuronal this way!\n",
    "# simulateBOLD.warmUpFactor = 6.\n",
    "simulateBOLD.Tmaxneuronal = (Tmax-1) * simulateBOLD.TR + 30\n",
    "integrator.ds = simulateBOLD.TR  # record every TR millisecond\n",
    "\n",
    "# Hopf.beta = 0.01\n",
    "f_diff = filtPowSpectr.filtPowSpetraMultipleSubjects(timeseries, TR=3.)  # should be baseline_group_ts .. or baseling_group[0].reshape((1,52,193))\n",
    "f_diff[np.where(f_diff == 0)] = np.mean(f_diff[np.where(f_diff != 0)])  # f_diff(find(f_diff==0))=mean(f_diff(find(f_diff~=0)))\n",
    "\n",
    "Hopf.omega = 2 * np.pi * f_diff\n",
    "\n",
    "print(\"ADHopf Setup done!\")\n",
    "\n",
    "\n",
    "base_a_value = -0.02\n",
    "warmUp = True\n",
    "warmUpFactor = 10.\n",
    "\n",
    "def computeSubjectSimulation():\n",
    "    # integrator.neuronalModel.SC = C\n",
    "    # integrator.initBookkeeping(N, Tmaxneuronal)\n",
    "    if warmUp:\n",
    "        currObsVars = integrator.warmUpAndSimulate(dt, Tmaxneuronal, TWarmUp=Tmaxneuronal/warmUpFactor)\n",
    "    else:\n",
    "        currObsVars = integrator.simulate(dt, Tmaxneuronal)\n",
    "    # currObsVars = integrator.returnBookkeeping()  # curr_xn, curr_rn\n",
    "    neuro_act = currObsVars[:,1,:]  # curr_rn\n",
    "    return neuro_act\n",
    "    \n",
    "\n",
    "def loadXBurden(condition):\n",
    "    # ------------------- load and stack the different wm burdens\n",
    "    wm_hc = np.load('/home/riccardo/ADNI_Hopf/Results/wmh_volumes_HC.npy')\n",
    "    wm_mci = np.load('/home/riccardo/ADNI_Hopf/Results/wmh_volumes_MCI.npy')\n",
    "    wm_overall = np.load('/home/riccardo/ADNI_Hopf/Results/wmh_volumes_ALL.npy')\n",
    "    # ------------------- load the specific subject wm\n",
    "    if condition == 'hc':\n",
    "        wmBurden = wm_hc\n",
    "    elif condition == 'mci':\n",
    "        wmBurden = wm_mci\n",
    "    elif condition == 'all':\n",
    "        wmBurden = wm_overall\n",
    "    # ------------------- normalize and return\n",
    "    # wmBurdenNorm = (wmBurden - np.min(wmBurden))/np.ptp(wmBurden)  # Normalize each individual in [0,1]\n",
    "    wmBurdenNorm = (wmBurden - np.min(wm_overall))/np.ptp(wm_overall)  # Normalize the whole group in [0,1]\n",
    "    return wmBurdenNorm\n",
    "\n",
    "# ------------ load wm burden\n",
    "conditionToStudy='all' #lower case, can be hc or mci or all\n",
    "wmBurden = loadXBurden(conditionToStudy)\n",
    "mode = 'homogeneous'  # homogeneous/heterogeneous\n",
    "\n",
    "# Note that this homogeneous is intended as homogeneous inside the same patient, so all regions of one patient have the same wmBurden, but different patients have different wmBurdens.\n",
    "# Heterogenous, instead, means that different regions in the same patient have different wmBurdens\n",
    "if mode == 'homogeneous':\n",
    "    #avgwm = np.average(wmBurden)\n",
    "    wmBurden = np.array([np.ones([nNodes]) * wmBurden[i] for i in range(len(wmBurden))])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################################################\n",
      "# Fitting (scaling)\n",
      "###################################################################\n",
      "\n",
      "All output logs can be found in directory  /home/riccardo/ADNI_Hopf/Code/Hopf_simulation/Python/HopfGustavoPatow_new/WholeBrain/Data_Produced/L2L-ADHopf-Prepro/logs\n",
      "JUBE parameters used: {'submit_cmd': 'sbatch', 'job_file': 'job.run', 'nodes': '1', 'walltime': '01:00:00', 'ppn': '1', 'cpu_pp': '1', 'threads_pp': '4', 'mail_mode': 'ALL', 'err_file': 'stderr', 'out_file': 'stdout', 'tasks_per_job': '1', 'exec': 'python3 /home/riccardo/ADNI_Hopf/Code/Hopf_simulation/Python/HopfGustavoPatow_new/WholeBrain/Data_Produced/L2L-ADHopf-Prepro/simulation/run_files/run_optimizee.py', 'ready_file': '/home/riccardo/ADNI_Hopf/Code/Hopf_simulation/Python/HopfGustavoPatow_new/WholeBrain/Data_Produced/L2L-ADHopf-Prepro/ready_files/ready_w_', 'work_path': '/home/riccardo/ADNI_Hopf/Code/Hopf_simulation/Python/HopfGustavoPatow_new/WholeBrain/Data_Produced/L2L-ADHopf-Prepro', 'paths_obj': <l2l.paths.Paths object at 0x7fe9e6c5b8e0>}\n",
      "Loading file (@loadOrCompute): /home/riccardo/ADNI_Hopf/Results/Prove/fNeuro_emp_L2L.mat !!!\n",
      "MainProcess bin.l2l LAPTOP-3SB6B8L7 2004 INFO    : Optimizee parameters: <class '__main__.OptimizeeParameters'>\n",
      "MainProcess bin.l2l LAPTOP-3SB6B8L7 2004 INFO    : Optimizer parameters: GridSearchParameters(param_grid={'scaling': (-0.1, 0.1, 5)})\n",
      "Computing (@loadOrCompute): /home/riccardo/ADNI_Hopf/Results/Prove/fitting_scaling-0.1_homogeneous-L2L.mat\n",
      "   Going to eval: {'scaling': -0.1}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unable to broadcast argument 3 to output array\nFile \"/home/riccardo/ADNI_Hopf/Code/Hopf_simulation/Python/HopfGustavoPatow_new/WholeBrain/WholeBrain/Integrator_EulerMaruyama.py\", line 1, ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [31], line 97\u001b[0m\n\u001b[1;32m     94\u001b[0m selectedObservable \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mFC\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     95\u001b[0m \u001b[39m# tauStart = 0.5\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[39m# tauWs = np.arange(tauStart, tauEnd + tauStep, tauStep)\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m optimal \u001b[39m=\u001b[39m fittingPipelineL2L(all_fMRI, distanceSettings, selectedObservable)\n\u001b[1;32m     98\u001b[0m \u001b[39m# ------- Save result\u001b[39;00m\n\u001b[1;32m     99\u001b[0m sio\u001b[39m.\u001b[39msavemat(outFilePath \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/fittingResult-scaling-\u001b[39m\u001b[39m{\u001b[39;00mmode\u001b[39m}\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m{\u001b[39;00mselectedObservable\u001b[39m}\u001b[39;00m\u001b[39m.mat\u001b[39m\u001b[39m'\u001b[39m, optimal)\n",
      "Cell \u001b[0;32mIn [31], line 77\u001b[0m, in \u001b[0;36mfittingPipelineL2L\u001b[0;34m(all_fMRI, distanceSettings, selectedObservable)\u001b[0m\n\u001b[1;32m     69\u001b[0m optimizer_parameters \u001b[39m=\u001b[39m GridSearchParameters(param_grid\u001b[39m=\u001b[39m{\n\u001b[1;32m     70\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mscaling\u001b[39m\u001b[39m'\u001b[39m: (\u001b[39m-\u001b[39m\u001b[39m0.1\u001b[39m, \u001b[39m0.1\u001b[39m, \u001b[39mint\u001b[39m((\u001b[39m0.1\u001b[39m\u001b[39m+\u001b[39m\u001b[39m0.05\u001b[39m\u001b[39m-\u001b[39m(\u001b[39m-\u001b[39m\u001b[39m0.1\u001b[39m))\u001b[39m/\u001b[39m\u001b[39m0.05\u001b[39m))\n\u001b[1;32m     71\u001b[0m })\n\u001b[1;32m     72\u001b[0m optimizer \u001b[39m=\u001b[39m GridSearchOptimizer(traj,\n\u001b[1;32m     73\u001b[0m                                 optimizee_create_individual\u001b[39m=\u001b[39moptimizee\u001b[39m.\u001b[39mcreate_individual,\n\u001b[1;32m     74\u001b[0m                                 optimizee_fitness_weights\u001b[39m=\u001b[39m(\u001b[39m-\u001b[39m\u001b[39m1.\u001b[39m,),  \u001b[39m# minimize!\u001b[39;00m\n\u001b[1;32m     75\u001b[0m                                 parameters\u001b[39m=\u001b[39moptimizer_parameters)\n\u001b[0;32m---> 77\u001b[0m experiment\u001b[39m.\u001b[39;49mrun_experiment(optimizee\u001b[39m=\u001b[39;49moptimizee,\n\u001b[1;32m     78\u001b[0m                           optimizee_parameters\u001b[39m=\u001b[39;49moptimizee_parameters,\n\u001b[1;32m     79\u001b[0m                           optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m     80\u001b[0m                           optimizer_parameters\u001b[39m=\u001b[39;49moptimizer_parameters)\n\u001b[1;32m     81\u001b[0m experiment\u001b[39m.\u001b[39mend_experiment(optimizer)\n\u001b[1;32m     82\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbest: scaling=\u001b[39m\u001b[39m{\u001b[39;00mexperiment\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mbest_individual[\u001b[39m'\u001b[39m\u001b[39mscaling\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/Learning_to_Learn-1.0.0b0-py3.9.egg/l2l/utils/experiment.py:170\u001b[0m, in \u001b[0;36mExperiment.run_experiment\u001b[0;34m(self, optimizer, optimizee, optimizer_parameters, optimizee_parameters)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39madd_postprocessing(optimizer\u001b[39m.\u001b[39mpost_process)\n\u001b[1;32m    169\u001b[0m \u001b[39m# Run the simulation\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrun(optimizee\u001b[39m.\u001b[39;49msimulate)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/Learning_to_Learn-1.0.0b0-py3.9.egg/l2l/utils/environment.py:109\u001b[0m, in \u001b[0;36mEnvironment.run\u001b[0;34m(self, runfunc)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogging:\n\u001b[1;32m    105\u001b[0m             logger\u001b[39m.\u001b[39mexception(\n\u001b[1;32m    106\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mError during serial execution \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mof individuals: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e\u001b[39m.\u001b[39m__cause__)\n\u001b[1;32m    108\u001b[0m             )\n\u001b[0;32m--> 109\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    111\u001b[0m \u001b[39m# Add results to the trajectory\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrajectory\u001b[39m.\u001b[39mresults\u001b[39m.\u001b[39mf_add_result_to_group(\n\u001b[1;32m    113\u001b[0m                                     \u001b[39m\"\u001b[39m\u001b[39mall_results\u001b[39m\u001b[39m\"\u001b[39m, it, result[it])\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/Learning_to_Learn-1.0.0b0-py3.9.egg/l2l/utils/environment.py:96\u001b[0m, in \u001b[0;36mEnvironment.run\u001b[0;34m(self, runfunc)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39mfor\u001b[39;00m ind \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrajectory\u001b[39m.\u001b[39mindividuals[it]:\n\u001b[1;32m     95\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrajectory\u001b[39m.\u001b[39mindividual \u001b[39m=\u001b[39m ind\n\u001b[0;32m---> 96\u001b[0m     fitness \u001b[39m=\u001b[39m runfunc(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrajectory)\n\u001b[1;32m     97\u001b[0m     result[it]\u001b[39m.\u001b[39mappend((ind\u001b[39m.\u001b[39mind_idx, fitness))\n\u001b[1;32m     98\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_id \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_id \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/ADNI_Hopf/Code/Hopf_simulation/Python/HopfGustavoPatow_new/WholeBrain/WholeBrain/Optimizers/L2LOptimizee.py:106\u001b[0m, in \u001b[0;36mWholeBrainOptimizee.simulate\u001b[0;34m(self, trajectory)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39m# Start simulation\u001b[39;00m\n\u001b[1;32m    105\u001b[0m filename \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilenamePattern\u001b[39m.\u001b[39mformat(parm2filename(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx))\n\u001b[0;32m--> 106\u001b[0m fitness \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msimulate_(filename)[measure\u001b[39m.\u001b[39mname]  \u001b[39m# For the @loadOrCompute wrapper to work, all WholeBrain should return dicts\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m  Value:\u001b[39m\u001b[39m\"\u001b[39m, fitness, \u001b[39m\"\u001b[39m\u001b[39m@\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx, flush\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    108\u001b[0m \u001b[39m# Return the last correlation coefficient as fitness of the model\u001b[39;00m\n",
      "File \u001b[0;32m~/ADNI_Hopf/Code/Hopf_simulation/Python/HopfGustavoPatow_new/WholeBrain/WholeBrain/Utils/decorators.py:55\u001b[0m, in \u001b[0;36mloadOrCompute.<locals>.loading_decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m verbose: \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mComputing (@loadOrCompute): \u001b[39m\u001b[39m{\u001b[39;00margs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, flush\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     54\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(a \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(args)[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[0;32m---> 55\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49mvalue)\n\u001b[1;32m     56\u001b[0m     sio\u001b[39m.\u001b[39msavemat(args[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], result)\n\u001b[1;32m     57\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/ADNI_Hopf/Code/Hopf_simulation/Python/HopfGustavoPatow_new/WholeBrain/WholeBrain/Optimizers/L2LOptimizee.py:84\u001b[0m, in \u001b[0;36mWholeBrainOptimizee.simulate_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m measureValues \u001b[39m=\u001b[39m measure\u001b[39m.\u001b[39minit(trials, N)\n\u001b[1;32m     83\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(trials):\n\u001b[0;32m---> 84\u001b[0m     bds \u001b[39m=\u001b[39m simulateBOLD\u001b[39m.\u001b[39;49msimulateSingleSubject()\u001b[39m.\u001b[39mT\n\u001b[1;32m     85\u001b[0m     procSignal \u001b[39m=\u001b[39m measure\u001b[39m.\u001b[39mfrom_fMRI(bds, applyFilters\u001b[39m=\u001b[39mapplyFilters)\n\u001b[1;32m     86\u001b[0m     measureValues \u001b[39m=\u001b[39m measure\u001b[39m.\u001b[39maccumulate(measureValues, i, procSignal)\n",
      "File \u001b[0;32m~/ADNI_Hopf/Code/Hopf_simulation/Python/HopfGustavoPatow_new/WholeBrain/WholeBrain/simulate_SimOnly.py:59\u001b[0m, in \u001b[0;36msimulateSingleSubject\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msimulateSingleSubject\u001b[39m():\n\u001b[1;32m     58\u001b[0m     \u001b[39m# N=C.shape[0]\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m     BOLD_act \u001b[39m=\u001b[39m computeSubjectSimulation()\n\u001b[1;32m     60\u001b[0m     \u001b[39m# now, (sub)sample the BOLD signal to obtain the final fMRI signal\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     n_min \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(np\u001b[39m.\u001b[39mround(t_min \u001b[39m/\u001b[39m dtt))\n",
      "File \u001b[0;32m~/ADNI_Hopf/Code/Hopf_simulation/Python/HopfGustavoPatow_new/WholeBrain/WholeBrain/simulate_SimOnly.py:45\u001b[0m, in \u001b[0;36mcomputeSubjectSimulation\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcomputeSubjectSimulation\u001b[39m():\n\u001b[1;32m     42\u001b[0m     \u001b[39m# integrator.neuronalModel.SC = C\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     \u001b[39m# integrator.initBookkeeping(N, Tmaxneuronal)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[39mif\u001b[39;00m warmUp:\n\u001b[0;32m---> 45\u001b[0m         currObsVars \u001b[39m=\u001b[39m integrator\u001b[39m.\u001b[39;49mwarmUpAndSimulate(dt, Tmaxneuronal, TWarmUp\u001b[39m=\u001b[39;49mTmaxneuronal\u001b[39m/\u001b[39;49mwarmUpFactor)\n\u001b[1;32m     46\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m         currObsVars \u001b[39m=\u001b[39m integrator\u001b[39m.\u001b[39msimulate(dt, Tmaxneuronal)\n",
      "File \u001b[0;32m~/ADNI_Hopf/Code/Hopf_simulation/Python/HopfGustavoPatow_new/WholeBrain/WholeBrain/Integrator_EulerMaruyama.py:138\u001b[0m, in \u001b[0;36mwarmUpAndSimulate\u001b[0;34m(dt, Tmaxneuronal, TWarmUp)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mWarming Up...\u001b[39m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m, flush\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    137\u001b[0m initStimuli(dt, TWarmUp)\n\u001b[0;32m--> 138\u001b[0m simVars, obsVars \u001b[39m=\u001b[39m integrate(dt, TWarmUp, simVars, doBookkeeping\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m verbose:\n\u001b[1;32m    140\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mand simulating!!!\u001b[39m\u001b[39m\"\u001b[39m, flush\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/ADNI_Hopf/Code/Hopf_simulation/Python/HopfGustavoPatow_new/WholeBrain/WholeBrain/Integrator_EulerMaruyama.py:116\u001b[0m, in \u001b[0;36mintegrate\u001b[0;34m(dt, Tmaxneuronal, simVars, doBookkeeping)\u001b[0m\n\u001b[1;32m    114\u001b[0m N \u001b[39m=\u001b[39m simVars\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]  \u001b[39m# N = neuronalModel.SC.shape[0]  # size(C,1) #N = CFile[\"Order\"].shape[1]\u001b[39;00m\n\u001b[1;32m    115\u001b[0m curr_obsVars \u001b[39m=\u001b[39m initBookkeeping(N, Tmaxneuronal)\n\u001b[0;32m--> 116\u001b[0m \u001b[39mreturn\u001b[39;00m integrationLoop(dt, Tmaxneuronal, simVars, doBookkeeping, curr_obsVars)\n",
      "File \u001b[0;32m~/ADNI_Hopf/Code/Hopf_simulation/Python/HopfGustavoPatow_new/WholeBrain/WholeBrain/Integrator_EulerMaruyama.py:104\u001b[0m, in \u001b[0;36mintegrationLoop\u001b[0;34m(dt, Tmaxneuronal, simVars, doBookkeeping, curr_obsVars)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39marange(\u001b[39m0\u001b[39m, Tmaxneuronal, dt):\n\u001b[1;32m    103\u001b[0m     stimulus \u001b[39m=\u001b[39m allStimuli[\u001b[39mint\u001b[39m(t \u001b[39m/\u001b[39m dt)]\n\u001b[0;32m--> 104\u001b[0m     simVars_obsVars \u001b[39m=\u001b[39m integrationStep(simVars, dt, stimulus)\n\u001b[1;32m    105\u001b[0m     simVars \u001b[39m=\u001b[39m simVars_obsVars[\u001b[39m0\u001b[39m]; obsVars \u001b[39m=\u001b[39m simVars_obsVars[\u001b[39m1\u001b[39m]  \u001b[39m# cannot use unpacking in numba...\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     \u001b[39mif\u001b[39;00m doBookkeeping:\n",
      "\u001b[0;31mValueError\u001b[0m: unable to broadcast argument 3 to output array\nFile \"/home/riccardo/ADNI_Hopf/Code/Hopf_simulation/Python/HopfGustavoPatow_new/WholeBrain/WholeBrain/Integrator_EulerMaruyama.py\", line 1, "
     ]
    }
   ],
   "source": [
    "outFilePath = '/home/riccardo/ADNI_Hopf/Results/Prove'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import WholeBrain.Utils.plotFitting as plotFitting\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# =====================================================================\n",
    "#                      Single Subject Pipeline:  L2L\n",
    "# =====================================================================\n",
    "# =====================================================================\n",
    "def setupFunc(parms):\n",
    "    wmW = parms['scaling']\n",
    "    # wmParms = [{'a': base_a_value + wmW * wmBurden} for wmW in wmWs]\n",
    "    neuronalModel.setParms({'a': base_a_value + wmW * wmBurden})\n",
    "\n",
    "\n",
    "N = nNodes\n",
    "NumTrials = 5\n",
    "def fittingPipelineL2L(all_fMRI,\n",
    "                       distanceSettings,  # This is a dictionary of {name: (distance module, apply filters bool)}\n",
    "                       selectedObservable):\n",
    "    from collections import namedtuple\n",
    "    from l2l.utils.experiment import Experiment\n",
    "    from l2l.optimizers.gridsearch import GridSearchOptimizer, GridSearchParameters\n",
    "    import WholeBrain.Optimizers.L2LOptimizee as WBOptimizee\n",
    "    from WholeBrain.Optimizers.preprocessSignal import processEmpiricalSubjects  # processBOLDSignals\n",
    "\n",
    "    # Model Simulations\n",
    "    # ------------------------------------------\n",
    "    # Now, optimize all alpha (B), beta (Z) values: determine optimal (B,Z) to work with\n",
    "    print(\"\\n\\n###################################################################\")\n",
    "    print(\"# Fitting (scaling)\")\n",
    "    print(\"###################################################################\\n\")\n",
    "    experiment = Experiment(root_dir_path='Data_Produced')\n",
    "    name = 'L2L-ADHopf-Prepro'\n",
    "    traj, _ = experiment.prepare_experiment(name=name, log_stdout=True, multiprocessing=False)\n",
    "\n",
    "    # Setup the WhileBrain optimizee\n",
    "    WBOptimizee.neuronalModel = neuronalModel\n",
    "    WBOptimizee.integrator = integrator\n",
    "    WBOptimizee.simulateBOLD = simulateBOLD\n",
    "\n",
    "    # for k in list(distanceSettings):\n",
    "    #     if k != selectedObservable:\n",
    "    #         del distanceSettings[k]\n",
    "    # distanceSettings = {'swFCD': (swFCD, True)}\n",
    "    # del distanceSettings['FC'], distanceSettings['swFCD'] #, distanceSettings['phFCD']\n",
    "    WBOptimizee.measure = distanceSettings[selectedObservable][0]  # Measure to use to compute the error\n",
    "    WBOptimizee.applyFilters = distanceSettings[selectedObservable][1]  # Whether to apply filters to the resulting signal or not\n",
    "    outEmpFileName = outFilePath + '/fNeuro_emp_L2L.mat'\n",
    "    WBOptimizee.processedEmp = processEmpiricalSubjects(all_fMRI,\n",
    "                                                        distanceSettings,\n",
    "                                                        outEmpFileName)[selectedObservable]  # reference values (e.g., empirical) to compare to.\n",
    "    WBOptimizee.N = N  # Number of regions in the parcellation\n",
    "    WBOptimizee.trials = NumTrials  # Number of trials to try\n",
    "    optimizee_parameters = namedtuple('OptimizeeParameters', [])\n",
    "\n",
    "    filePattern = outFilePath + ('/fitting_{}_L2L.mat' if mode != 'homogeneous' else '/fitting_{}_homogeneous-L2L.mat')\n",
    "    optimizee = WBOptimizee.WholeBrainOptimizee(traj, {'scaling': (-0.1, 0.1)}, setupFunc=setupFunc, outFilenamePattern=filePattern)\n",
    "\n",
    "    # =================== Test for debug only\n",
    "    # traj.individual = sdict(optimizee.create_individual())\n",
    "    # testing_error = optimizee.simulate(traj)\n",
    "    # print(\"Testing error is %s\", testing_error)\n",
    "    # =================== end Test\n",
    "\n",
    "    # Setup the GridSearchOptimizer\n",
    "    optimizer_parameters = GridSearchParameters(param_grid={\n",
    "        'scaling': (-0.1, 0.1, int((0.1+0.05-(-0.1))/0.05))\n",
    "    })\n",
    "    optimizer = GridSearchOptimizer(traj,\n",
    "                                    optimizee_create_individual=optimizee.create_individual,\n",
    "                                    optimizee_fitness_weights=(-1.,),  # minimize!\n",
    "                                    parameters=optimizer_parameters)\n",
    "\n",
    "    experiment.run_experiment(optimizee=optimizee,\n",
    "                              optimizee_parameters=optimizee_parameters,\n",
    "                              optimizer=optimizer,\n",
    "                              optimizer_parameters=optimizer_parameters)\n",
    "    experiment.end_experiment(optimizer)\n",
    "    print(f\"best: scaling={experiment.optimizer.best_individual['scaling']}\")\n",
    "    return {'subject': subjectName, 'value': experiment.optimizer.best_fitness, 'parms': experiment.optimizer.best_individual['scaling']}\n",
    "\n",
    "\n",
    "\n",
    "subj_list = np.load('/home/riccardo/ADNI_Hopf/Results/subject_list_timeseries_all.npy')\n",
    "\n",
    "subjectName = ''\n",
    "warmUp = True\n",
    "warmUpFactor = 10.\n",
    "\n",
    "neuronalModel.setParms({'we': 2.9})\n",
    "selectedObservable = 'FC'\n",
    "# tauStart = 0.5\n",
    "# tauWs = np.arange(tauStart, tauEnd + tauStep, tauStep)\n",
    "optimal = fittingPipelineL2L(all_fMRI, distanceSettings, selectedObservable)\n",
    "# ------- Save result\n",
    "sio.savemat(outFilePath + f'/fittingResult-scaling-{mode}-{selectedObservable}.mat', optimal)\n",
    "\n",
    "\n",
    "# def fittingPipeline_heterogeneous(all_fMRI, wmBurden, wmWs):\n",
    "#     best_parameters_dict = {}\n",
    "#     for k, subjectName in enumerate(subj_list):\n",
    "#         subj_fMRI = {k:all_fMRI[k]}\n",
    "#         wmBurden_subj = wmBurden[k]\n",
    "#         best_parameters = fittingPipeline_homogeneous(subj_fMRI=subj_fMRI, distanceSettings=distanceSettings, subjectName=subjectName, wms=wmWs, wmBurden = wmBurden_subj)\n",
    "#         best_parameters_dict[subjectName] = best_parameters\n",
    "#     return best_parameters_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('neurolib': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18e43de8b878494df763bc7045d8b6860d297bafdd730193e66e4d65bb98bce4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
