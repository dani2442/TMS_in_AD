{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCnorm.shape=(78, 78)\n",
      "filtPowSpetraMultipleSubjects: subject 0 (of 14)\n",
      "filtPowSpetraMultipleSubjects: subject 1 (of 14)\n",
      "filtPowSpetraMultipleSubjects: subject 2 (of 14)\n",
      "filtPowSpetraMultipleSubjects: subject 3 (of 14)\n",
      "filtPowSpetraMultipleSubjects: subject 4 (of 14)\n",
      "filtPowSpetraMultipleSubjects: subject 5 (of 14)\n",
      "filtPowSpetraMultipleSubjects: subject 6 (of 14)\n",
      "filtPowSpetraMultipleSubjects: subject 7 (of 14)\n",
      "filtPowSpetraMultipleSubjects: subject 8 (of 14)\n",
      "filtPowSpetraMultipleSubjects: subject 9 (of 14)\n",
      "filtPowSpetraMultipleSubjects: subject 10 (of 14)\n",
      "filtPowSpetraMultipleSubjects: subject 11 (of 14)\n",
      "filtPowSpetraMultipleSubjects: subject 12 (of 14)\n",
      "filtPowSpetraMultipleSubjects: subject 13 (of 14)\n",
      "ADHopf Setup done!\n"
     ]
    }
   ],
   "source": [
    "# Load all the packages needed for analyses\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from numba import jit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up Hopf as our model \n",
    "import WholeBrain.Models.supHopf as Hopf\n",
    "from WholeBrain.simulate_SimOnly import Tmaxneuronal\n",
    "Hopf.initialValue = 0.1\n",
    "neuronalModel = Hopf\n",
    "\n",
    "# Set up our integrator\n",
    "import WholeBrain.Integrator_EulerMaruyama as myIntegrator\n",
    "integrator = myIntegrator\n",
    "integrator.neuronalModel = neuronalModel\n",
    "integrator.verbose = False\n",
    "integrator.clamping = False\n",
    "\n",
    "# Set up the integration parameters\n",
    "dt = 5e-5\n",
    "# tmax is equal to the number of timepoints: 193\n",
    "tmax= 193\n",
    "ds = 1e-4\n",
    "Tmaxneuronal = int((tmax+dt))\n",
    "\n",
    "import WholeBrain.simulate_SimOnly as simulateBOLD\n",
    "simulateBOLD.warmUp = True\n",
    "simulateBOLD.integrator = integrator\n",
    "simulateBOLD.warmUpFactor = 606./2000.\n",
    "\n",
    "# Set up the code to obtain the variables we want to maximize similarity to empirical FC\n",
    "import WholeBrain.Observables.FC as FC\n",
    "import WholeBrain.Observables.phFCD as phFCD\n",
    "\n",
    "# Import the optimizer function\n",
    "import WholeBrain.Optimizers.ParmSeep as ParmSeep\n",
    "ParmSeep.simulateBOLD = simulateBOLD\n",
    "ParmSeep.integrator = integrator\n",
    "ParmSeep.verbose = True\n",
    "\n",
    "\n",
    "# set BOLD filter settings\n",
    "import WholeBrain.Utils.filteredPowerSpectralDensity as filtPowSpectr\n",
    "import WholeBrain.BOLDFilters as BOLDfilters\n",
    "\n",
    "# For sure these filters are applied in the filtPowSpectr function that we use to calculate the intrinsic frequencies of each region.\n",
    "# They are also applied to process the FC and swFCD, but you can set the corresponding parameter to False later on. 0.04-0.07 Hz common to extract intrinsic frequenci\n",
    "BOLDfilters.flp = 0.04\n",
    "BOLDfilters.fhi = 0.07\n",
    "BOLDfilters.TR = 3.0\n",
    "\n",
    "# Get the list of names of all regions in the AAL atlas. This is needed to get the right indices, to then filter the FC\n",
    "import csv\n",
    "# This is a sublist of label of the cortical regions that were included in the paper by Demirtas et al. - AAL atlas (78 regions, excluding infratentorial and deep)\n",
    "with open ('/home/riccardo/ADNI_Hopf/Utils/aal_regions_included.csv', newline='') as g:\n",
    "    new_reader = csv.reader(g)\n",
    "    included_regions = list(new_reader)\n",
    "g.close()\n",
    "\n",
    "# Get the AAL atlas labels\n",
    "import nilearn.datasets as datasets\n",
    "aal = datasets.fetch_atlas_aal()\n",
    "labels = np.array(aal.labels)\n",
    "# create an array with the indices of each label (note that these are not the label number from the nifti image)\n",
    "indices = np.array([i for i in enumerate(labels)])\n",
    "FC_regions_index = np.isin(labels, included_regions)\n",
    "# filter the indices that we want based on the position \n",
    "FC_78_regions_aal_atlas = indices[FC_regions_index]\n",
    "filter_FC = np.array([int(i) for i in FC_78_regions_aal_atlas[:,0]])\n",
    "\n",
    "# Set file path.\n",
    "x_path = '/home/riccardo/ADNI_Hopf/Utils/'\n",
    "\n",
    "# Load structural connectivity matrix and use it as parameter in Hopf model\n",
    "xfile = 'SCmatrices88healthy.mat' \n",
    "M = sio.loadmat(x_path + xfile); \n",
    "mat = M['SCmatrices']\n",
    "# averaging the SC among subjects\n",
    "mat0 = np.mean(mat,axis = 0)\n",
    "# filter in order to have only the regions we want\n",
    "x_mat0 = mat0[filter_FC]\n",
    "new_mat0 = x_mat0.T[filter_FC]\n",
    "# standardize the SC matrix and scale it to prevent the full synchronization of the model\n",
    "SCnorm = new_mat0 * 0.2 / new_mat0.max() \n",
    "np.fill_diagonal(SCnorm,0)\n",
    "print('SCnorm.shape={}'.format(new_mat0.shape))    \n",
    "\n",
    "# Set the structural connectivity matrix of the Hopf model to the SC we just created\n",
    "Hopf.setParms({'SC':SCnorm})\n",
    "\n",
    "#  Load the timeseries for our group\n",
    "timeseries = np.load('/home/riccardo/ADNI_Hopf/Results/timeseries_HC.npy')\n",
    "nsubjects, nNodes, Tmax = timeseries.shape\n",
    "# Create the dictionary for each patient\n",
    "all_fMRI = {s: d for s,d in enumerate(timeseries)} \n",
    "subjectName = ''\n",
    "conditionToStudy='mci'\n",
    "mode = 'heterogeneous'  # homogeneous/heterogeneous\n",
    "# here we set if we want to apply the BOLD filters or not. I am not sure if it is best to apply them when I extract the signal or later, but applying them multiple times\n",
    "# should influence the results, from what I understood.\n",
    "distanceSettings = {'FC': (FC, False), 'swFCD': (swFCD, False), 'phFCD': (phFCD, False)} \n",
    "\n",
    "simulateBOLD.TR = 3.  # Recording interval: 1 sample every 3 seconds\n",
    "simulateBOLD.dt = 0.1 * simulateBOLD.TR / 2.\n",
    "simulateBOLD.Tmax = Tmax  # This is the length, in seconds\n",
    "simulateBOLD.dtt = simulateBOLD.TR  # We are not using milliseconds\n",
    "simulateBOLD.t_min = 10 * simulateBOLD.TR\n",
    "# simulateBOLD.recomputeTmaxneuronal() <- do not update Tmaxneuronal this way!\n",
    "# simulateBOLD.warmUpFactor = 6.\n",
    "simulateBOLD.Tmaxneuronal = (Tmax-1) * simulateBOLD.TR + 30\n",
    "integrator.ds = simulateBOLD.TR  # record every TR millisecond\n",
    "\n",
    "# Set the base G value = 2.55 as it was found in the previous scripts.\n",
    "base_G_value = 2.55\n",
    "Hopf.setParms({'we': base_G_value})\n",
    "# Hopf.beta = 0.01\n",
    "f_diff = filtPowSpectr.filtPowSpetraMultipleSubjects(timeseries, TR=3.)  # should be baseline_group_ts .. or baseling_group[0].reshape((1,52,193))\n",
    "f_diff[np.where(f_diff == 0)] = np.mean(f_diff[np.where(f_diff != 0)])  # f_diff(find(f_diff==0))=mean(f_diff(find(f_diff~=0)))\n",
    "Hopf.omega = 2 * np.pi * f_diff\n",
    "\n",
    "print(\"ADHopf Setup done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outFilePath = '/home/riccardo/ADNI_Hopf/Results/Modeling/Prove'\n",
    "\n",
    "warmUp = True\n",
    "warmUpFactor = 10.\n",
    "\n",
    "def computeSubjectSimulation():\n",
    "    # integrator.neuronalModel.SC = C\n",
    "    # integrator.initBookkeeping(N, Tmaxneuronal)\n",
    "    if warmUp:\n",
    "        currObsVars = integrator.warmUpAndSimulate(dt, Tmaxneuronal, TWarmUp=Tmaxneuronal/warmUpFactor)\n",
    "    else:\n",
    "        currObsVars = integrator.simulate(dt, Tmaxneuronal)\n",
    "    # currObsVars = integrator.returnBookkeeping()  # curr_xn, curr_rn\n",
    "    neuro_act = currObsVars[:,1,:]  # curr_rn\n",
    "    return neuro_act\n",
    "    \n",
    "Gs = np.array([2.55])\n",
    "\n",
    "def fittingPipeline_homogeneous(all_fMRI,\n",
    "                    distanceSettings,  # This is a dictionary of {name: (distance module, apply filters bool)}\n",
    "                    gs):\n",
    "    print(\"\\n\\n###################################################################\")\n",
    "    print(\"# Fitting with ParmSeep\")\n",
    "    print(\"###################################################################\\n\")\n",
    "    # Now, optimize all we (G) values: determine optimal G to work with\n",
    "    gParms = [{'we': g} for g in Gs]\n",
    "    fitting = ParmSeep.distanceForAll_Parms(all_fMRI,\n",
    "                                            Gs, \n",
    "                                            gParms,\n",
    "                                            NumSimSubjects=len(all_fMRI),\n",
    "                                            distanceSettings=distanceSettings,\n",
    "                                            parmLabel='Homogeneous_a_G_',\n",
    "                                            outFilePath=outFilePath)\n",
    "\n",
    "    optimal = {sd: distanceSettings[sd][0].findMinMax(fitting[sd]) for sd in distanceSettings}\n",
    "    return optimal\n",
    "\n",
    "\n",
    "best_parameters = fittingPipeline_homogeneous(all_fMRI=all_fMRI, distanceSettings=distanceSettings, gs=Gs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('neurolib': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18e43de8b878494df763bc7045d8b6860d297bafdd730193e66e4d65bb98bce4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
