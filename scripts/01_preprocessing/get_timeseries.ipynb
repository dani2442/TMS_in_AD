{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the needed packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bids import BIDSLayout\n",
    "\n",
    "from nilearn.interfaces import fmriprep\n",
    "from nilearn import datasets\n",
    "from nilearn.maskers import NiftiLabelsMasker\n",
    "from nilearn import image as nimg\n",
    "from nilearn.signal import clean \n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "import scipy.io as sio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a40f16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/riccardo/ADNI_Hopf'\n",
    "BIDS_dir = base_dir + '/Data/ALL'\n",
    "# set the layout variable to the BIDS-folder where your WMH are located\n",
    "layout = BIDSLayout(BIDS_dir, validate = False, config = ['bids', 'derivatives'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2febc16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the subject list\n",
    "subjs = layout.get_subjects()\n",
    "\n",
    "#Create an empty list to store patients to exclude due to high motion artifacts, described as mean RMS framewise-displacement > 0.2 mm or > 20 volumes with RMS FD > 0.25 mm (as per \"Benchmarking...\" Ciric et al. paper)\n",
    "motion_exclusion_list = []\n",
    "\n",
    "for subj in subjs:\n",
    "    # get the confounds.tsv table storing all confounds\n",
    "    confounds = layout.get(subject = subj, extension = 'tsv',\n",
    "               datatype = 'func',\n",
    "               desc = 'confounds',\n",
    "               return_type = 'file')\n",
    "    confound_file = confounds[0]\n",
    "    # create pandas dataframe for filtering\n",
    "    df_confounds = pd.read_csv(confound_file, delimiter = '\\t') \n",
    "    # get patient names if gross motion artifacts and store them in the list\n",
    "    if df_confounds['rmsd'].mean() > 0.2 or df_confounds[df_confounds['rmsd'] > 0.25].count()[0] > 20:     \n",
    "        motion_exclusion_list.append(subj)\n",
    "     \n",
    "#filter patients to retain just patients without gross motion artifacts     \n",
    "new_subjs = [subj for subj in subjs if subj not in motion_exclusion_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb31f460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understand if patients are HC or MCI. Note that this is not proper BIDS, need to change in the future when having the final project. For example, it will be just easy to use a csv file or txt with patient names divided by MCI or HC\n",
    "subjs_MCI = BIDSLayout('/home/riccardo/ADNI_Hopf/Data/MCI/', validate = False, config = ['bids', 'derivatives'])\n",
    "MCI_subjs_initial = subjs_MCI.get_subjects()\n",
    "MCI_subjs = [MCI for MCI in new_subjs if MCI in MCI_subjs_initial]\n",
    "HC_subjs = [HC for HC in new_subjs if HC not in MCI_subjs]\n",
    "MCI_subjs.sort()\n",
    "HC_subjs.sort()\n",
    "# print(f'These are the MCI subjects:{MCI_subjs}')\n",
    "# print(f'These are the HC subjects:{HC_subjs}')\n",
    "# # for motion in motion_exclusion_list:\n",
    "# #     if motion in HC_subjs:\n",
    "# #         print(f'{motion} is a healthy control')\n",
    "# #     elif motion in MCI_subjs:\n",
    "# #         print(f'{motion} is a MCI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c463e45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the list of the included subjects: ['ADNI002S1155', 'ADNI002S4229', 'ADNI002S4654', 'ADNI002S4799', 'ADNI002S5178', 'ADNI002S6456', 'ADNI003S6258', 'ADNI003S6259', 'ADNI003S6268', 'ADNI003S6307', 'ADNI003S6432', 'ADNI006S6291', 'ADNI006S6651', 'ADNI011S6618', 'ADNI014S6424', 'ADNI018S2155', 'ADNI018S6414', 'ADNI019S6186', 'ADNI024S4674', 'ADNI024S6033', 'ADNI037S4214', 'ADNI037S4706', 'ADNI037S6083', 'ADNI068S2187', 'ADNI068S4431', 'ADNI070S6236', 'ADNI100S4556']\n"
     ]
    }
   ],
   "source": [
    "# Get the 78 region AAL atlas and its labels\n",
    "atlas_filename = base_dir + '/Utils/AAL_atlas_78Regions.nii.gz'\n",
    "\n",
    "import csv\n",
    "# open the csv containing the names of the 78 cortical regions that we will use \n",
    "with open(base_dir + '/Utils/aal_regions_included.csv', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    included_regions = list(reader)\n",
    "f.close()\n",
    "\n",
    "#create a 1-D array with the names so that it is more easily iterable\n",
    "included_regions_array = np.array([included_regions]).flatten()\n",
    "\n",
    "new_subjs.sort()\n",
    "print(f'This is the list of the included subjects: {new_subjs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "096487de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is the main function at the moment, where we perform 36P confound regression with no scrubbing.\n",
    "\n",
    "def get_fmri(subj):\n",
    "\n",
    "    func_images_file = layout.get(subject = subj, datatype='func', task='rest',\n",
    "                   desc='preproc',\n",
    "                   space='MNI152NLin2009cAsym',\n",
    "                   extension='nii.gz',\n",
    "                   return_type='file')\n",
    "\n",
    "    return func_images_file[0] \n",
    "\n",
    "def process_timeseries_36P(func_image, func_image_smoothed, use_filter, filt_low, filt_high, TR):\n",
    "\n",
    "    masker = NiftiLabelsMasker(labels_img=atlas_filename)\n",
    "    signal = masker.fit_transform(func_image_smoothed)\n",
    "    # exclude the first 4 timepoints and the infratentorial regions (which are the last 26 of the labels)\n",
    "    signal_selected = signal[4:,:90]\n",
    "    # Here we are applying a 36P confound regression strategy with motion parameters, derivatives and power of parameters and derivatives. We are excluding the first 4 timepoints. No scrubbing.\n",
    "    confounds, mask = fmriprep.load_confounds(func_image, strategy=('motion', 'wm_csf'), \n",
    "                                                        motion='full', wm_csf='full')\n",
    "    confounds_selected = confounds.iloc[4:,:]\n",
    "    if use_filter == True:\n",
    "        cleaned_signal = clean(signal_selected, detrend=True, standardize='zscore', confounds=confounds_selected, standardize_confounds=True, filter='butterworth', low_pass=filt_low, high_pass=filt_high, t_r=TR, ensure_finite=False)\n",
    "    else:\n",
    "        cleaned_signal = clean(signal_selected, detrend=True, standardize='zscore', confounds=confounds_selected, standardize_confounds=True, ensure_finite=False)\n",
    "\n",
    "    return cleaned_signal.T\n",
    "    \n",
    "\n",
    "# Get the timeseries divided according to the AAL atlas\n",
    "def extract_timeseries_group(subjs, use_filter, filt_low=0.08, filt_high=0.008, TR=3):\n",
    "\n",
    "    timeseries = np.zeros([len(subjs), included_regions_array.shape[0], 193])\n",
    "   \n",
    "    for n, subj in enumerate(subjs):\n",
    "        \n",
    "        print(f'Processing subject {subj}... ({n+1}/{len(subjs)})')\n",
    "        func_image = get_fmri(subj)\n",
    "        print(f'--Smoothing image for {subj}... ({n+1}/{len(subjs)})')\n",
    "        func_image_smoothed = nimg.smooth_img(func_image, 5)\n",
    "        func_image_smoothed_file = base_dir + f'/Temp/sub-{subj}_space-MNI152NLin2009cAsym_task-rest_desc-preprocSmoothed.nii.gz'\n",
    "        nib.save(func_image_smoothed, func_image_smoothed_file)\n",
    "        print(f'----Processing timeseries for {subj}... ({n+1}/{len(subjs)})')\n",
    "        ts = process_timeseries_36P(func_image, func_image_smoothed_file, use_filter, filt_low, filt_high, TR)\n",
    "        timeseries[n] = ts\n",
    "    \n",
    "    return timeseries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22bccb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject ADNI002S4799: 1/9\n",
      "Smoothing image for ADNI002S4799: 1/9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [39], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m use_filter \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m#filt_low = 0.08\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m#filt_high = 0.008\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m#TR = 3.\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m ts_HC \u001b[39m=\u001b[39m extract_timeseries_group(HC_subjs, use_filter)\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mDone for HC!\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m ts_MCI \u001b[39m=\u001b[39m extract_timeseries_group(MCI_subjs, use_filter)\n",
      "Cell \u001b[0;32mIn [13], line 41\u001b[0m, in \u001b[0;36mextract_timeseries_group\u001b[0;34m(subjs, use_filter, filt_low, filt_high, TR)\u001b[0m\n\u001b[1;32m     39\u001b[0m func_image \u001b[39m=\u001b[39m get_fmri(subj)\n\u001b[1;32m     40\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSmoothing image for \u001b[39m\u001b[39m{\u001b[39;00msubj\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mn\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(subjs)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 41\u001b[0m func_image_smoothed \u001b[39m=\u001b[39m nimg\u001b[39m.\u001b[39;49msmooth_img(func_image, \u001b[39m5\u001b[39;49m)\n\u001b[1;32m     42\u001b[0m func_image_smoothed_file \u001b[39m=\u001b[39m base_dir \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/Temp/sub-\u001b[39m\u001b[39m{\u001b[39;00msubj\u001b[39m}\u001b[39;00m\u001b[39m_space-MNI152NLin2009cAsym_task-rest_desc-preprocSmoothed.nii.gz\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     43\u001b[0m nib\u001b[39m.\u001b[39msave(func_image_smoothed, func_image_smoothed_file)\n",
      "File \u001b[0;32m~/anaconda3/envs/neurolib/lib/python3.9/site-packages/nilearn/image/image.py:275\u001b[0m, in \u001b[0;36msmooth_img\u001b[0;34m(imgs, fwhm)\u001b[0m\n\u001b[1;32m    273\u001b[0m ret \u001b[39m=\u001b[39m []\n\u001b[1;32m    274\u001b[0m \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m imgs:\n\u001b[0;32m--> 275\u001b[0m     img \u001b[39m=\u001b[39m check_niimg(img)\n\u001b[1;32m    276\u001b[0m     affine \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39maffine\n\u001b[1;32m    277\u001b[0m     filtered \u001b[39m=\u001b[39m _smooth_array(get_data(img), affine, fwhm\u001b[39m=\u001b[39mfwhm,\n\u001b[1;32m    278\u001b[0m                              ensure_finite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/neurolib/lib/python3.9/site-packages/nilearn/_utils/niimg_conversions.py:286\u001b[0m, in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[39mreturn\u001b[39;00m concat_niimgs(niimg, ensure_ndim\u001b[39m=\u001b[39mensure_ndim, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    285\u001b[0m \u001b[39m# Otherwise, it should be a filename or a SpatialImage, we load it\u001b[39;00m\n\u001b[0;32m--> 286\u001b[0m niimg \u001b[39m=\u001b[39m load_niimg(niimg, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    288\u001b[0m \u001b[39mif\u001b[39;00m ensure_ndim \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(niimg\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m4\u001b[39m \u001b[39mand\u001b[39;00m niimg\u001b[39m.\u001b[39mshape[\u001b[39m3\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    289\u001b[0m     \u001b[39m# \"squeeze\" the image.\u001b[39;00m\n\u001b[1;32m    290\u001b[0m     data \u001b[39m=\u001b[39m _safe_get_data(niimg)\n",
      "File \u001b[0;32m~/anaconda3/envs/neurolib/lib/python3.9/site-packages/nilearn/_utils/niimg.py:137\u001b[0m, in \u001b[0;36mload_niimg\u001b[0;34m(niimg, dtype)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(niimg, nibabel\u001b[39m.\u001b[39mspatialimages\u001b[39m.\u001b[39mSpatialImage):\n\u001b[1;32m    133\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mData given cannot be loaded because it is\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39m not compatible with nibabel format:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m                     \u001b[39m+\u001b[39m _repr_niimgs(niimg, shorten\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n\u001b[0;32m--> 137\u001b[0m dtype \u001b[39m=\u001b[39m _get_target_dtype(_get_data(niimg)\u001b[39m.\u001b[39mdtype, dtype)\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     \u001b[39m# Copyheader and set dtype in header if header exists\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m niimg\u001b[39m.\u001b[39mheader \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/neurolib/lib/python3.9/site-packages/nilearn/_utils/niimg.py:26\u001b[0m, in \u001b[0;36m_get_data\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mif\u001b[39;00m img\u001b[39m.\u001b[39m_data_cache \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39m_data_cache\n\u001b[0;32m---> 26\u001b[0m data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masanyarray(img\u001b[39m.\u001b[39;49m_dataobj)\n\u001b[1;32m     27\u001b[0m img\u001b[39m.\u001b[39m_data_cache \u001b[39m=\u001b[39m data\n\u001b[1;32m     28\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/neurolib/lib/python3.9/site-packages/nibabel/arrayproxy.py:370\u001b[0m, in \u001b[0;36mArrayProxy.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    350\u001b[0m     \u001b[39m\"\"\" Read data from file and apply scaling, casting to ``dtype``\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[1;32m    352\u001b[0m \u001b[39m    If ``dtype`` is unspecified, the dtype of the returned array is the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[39m        Scaled image data with type `dtype`.\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 370\u001b[0m     arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_scaled(dtype\u001b[39m=\u001b[39;49mdtype, slicer\u001b[39m=\u001b[39;49m())\n\u001b[1;32m    371\u001b[0m     \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    372\u001b[0m         arr \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/neurolib/lib/python3.9/site-packages/nibabel/arrayproxy.py:337\u001b[0m, in \u001b[0;36mArrayProxy._get_scaled\u001b[0;34m(self, dtype, slicer)\u001b[0m\n\u001b[1;32m    335\u001b[0m     scl_inter \u001b[39m=\u001b[39m scl_inter\u001b[39m.\u001b[39mastype(use_dtype)\n\u001b[1;32m    336\u001b[0m \u001b[39m# Read array and upcast as necessary for big slopes, intercepts\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m scaled \u001b[39m=\u001b[39m apply_read_scaling(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_unscaled(slicer\u001b[39m=\u001b[39;49mslicer), scl_slope, scl_inter)\n\u001b[1;32m    338\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m     scaled \u001b[39m=\u001b[39m scaled\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mpromote_types(scaled\u001b[39m.\u001b[39mdtype, dtype), copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/neurolib/lib/python3.9/site-packages/nibabel/volumeutils.py:900\u001b[0m, in \u001b[0;36mapply_read_scaling\u001b[0;34m(arr, slope, inter)\u001b[0m\n\u001b[1;32m    898\u001b[0m     arr \u001b[39m=\u001b[39m arr \u001b[39m*\u001b[39m slope\n\u001b[1;32m    899\u001b[0m \u001b[39mif\u001b[39;00m inter \u001b[39m!=\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[0;32m--> 900\u001b[0m     arr \u001b[39m=\u001b[39m arr \u001b[39m+\u001b[39;49m inter\n\u001b[1;32m    901\u001b[0m \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mreshape(shape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# If you want to filter, set use_filter = True and define the low_pass and high_pass filters for the Butterworth filter as well as the TR of your timeseries\n",
    "\n",
    "use_filter = False\n",
    "#filt_low = 0.08\n",
    "#filt_high = 0.008\n",
    "#TR = 3.\n",
    "\n",
    "\n",
    "ts_HC = extract_timeseries_group(HC_subjs, use_filter)\n",
    "print('Done for HC!')\n",
    "ts_MCI = extract_timeseries_group(MCI_subjs, use_filter)\n",
    "print('Done for MCI!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "759daea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save outputs\n",
    "np.save(base_dir + '/Results/subject_list_timeseries_HC.npy', np.array(HC_subjs))\n",
    "np.save(base_dir + '/Results/timeseries_HC.npy', ts_HC)\n",
    "# Save outputs\n",
    "np.save(base_dir + '/Results/subject_list_timeseries_MCI.npy', np.array(MCI_subjs))\n",
    "np.save(base_dir + '/Results/timeseries_MCI.npy', ts_MCI)\n",
    "\n",
    "# Create a concatenated timeseries for all patients \n",
    "new_subjs_all = HC_subjs + MCI_subjs\n",
    "timeseries_all = np.vstack([ts_HC, ts_MCI])\n",
    "# # Save outputs\n",
    "np.save(base_dir + '/Results/subject_list_timeseries_all.npy', np.array(new_subjs_all))\n",
    "np.save(base_dir + '/Results/timeseries_all.npy', timeseries_all)\n",
    "\n",
    "\n",
    "# Save it as a dictionary.. I still don't know which one is best to avoid possible errors...\n",
    "import pickle\n",
    "\n",
    "full_dictionary_timeseries = {subj:timeseries_all[n] for n, subj in enumerate(new_subjs_all)}\n",
    "f = open(base_dir + '/Results/dictionary_timeseries_all.pkl', 'wb')\n",
    "# write json object to file\n",
    "pickle.dump(full_dictionary_timeseries, f)\n",
    "# close file\n",
    "f.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('neurolib': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "18e43de8b878494df763bc7045d8b6860d297bafdd730193e66e4d65bb98bce4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
