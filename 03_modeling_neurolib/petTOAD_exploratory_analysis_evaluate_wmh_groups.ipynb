{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"   Gather results of the repeated simulations   -- Version 1.0\n",
    "Last edit:  2023/06/12\n",
    "Authors:    Leone, Riccardo (RL)\n",
    "Notes:      - Evaluate the different combinations of b and w\n",
    "            - Release notes:\n",
    "                * Initial release\n",
    "To do:      - \n",
    "Comments:   \n",
    "\n",
    "Sources: \n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from petTOAD_setup import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPL_DIR = RES_DIR / \"exploratory_first_round\"\n",
    "EXPL_FIG_DIR = EXPL_DIR / \"Figures\"\n",
    "if not Path.exists(EXPL_FIG_DIR):\n",
    "    Path.mkdir(EXPL_FIG_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_star(tbl):\n",
    "    star = tbl.where(tbl == tbl.values.max())\n",
    "    star = star.replace({np.nan: \"\"})\n",
    "    star = star.replace({tbl.values.max(): '*'})\n",
    "    return star\n",
    "\n",
    "def save_plot_results(res_df, group):\n",
    "    # Convert the result df into a pivot table so to plot heatmap\n",
    "    table_fc = pd.pivot_table(res_df, values='fc_pearson', index='b', columns='w').iloc[5:].astype(float)\n",
    "    table_fcd = pd.pivot_table(res_df, values='fcd_ks', index='b', columns='w').iloc[5:].astype(float)\n",
    "    table_phfcd = pd.pivot_table(res_df, values='phfcd_ks', index='b', columns='w').iloc[5:].astype(float)\n",
    "    # Create a composite score by summing up the single model fits\n",
    "    table_sum = table_fc + table_fcd + table_phfcd\n",
    "\n",
    "    # Create figure\n",
    "    fig, axs = plt.subplots(2,2, figsize = (14,14))\n",
    "    sns.heatmap(ax = axs[0,0],\n",
    "                data = table_fc,\n",
    "                annot = annotate_star(table_fc),\n",
    "                fmt = '', \n",
    "                annot_kws={\"size\": 10})\n",
    "    axs[0,0].set_title(f\"FC {group}\")\n",
    "\n",
    "    sns.heatmap(ax = axs[0,1],\n",
    "                data = table_fcd,\n",
    "                annot = annotate_star(table_fcd),\n",
    "                fmt = '', \n",
    "                annot_kws={\"size\": 10})\n",
    "    axs[0,1].set_title(f\"FCD {group}\")\n",
    "\n",
    "    sns.heatmap(ax = axs[1, 0],\n",
    "                data = table_phfcd, \n",
    "                annot = annotate_star(table_phfcd),\n",
    "                fmt = '', \n",
    "                annot_kws={\"size\": 10})\n",
    "    axs[1,0].set_title(f\"phFCD {group}\")\n",
    "    sns.heatmap(ax = axs[1,1],\n",
    "                data = table_sum, \n",
    "                annot = annotate_star(table_sum),\n",
    "                fmt = '', \n",
    "                annot_kws={\"size\": 10})\n",
    "    axs[1,1].set_title(f\"Sum of model fits {group}\")\n",
    "    plt.savefig(EXPL_DIR / f\"{group}_results_heatmap.png\")\n",
    "\n",
    "\n",
    "# Same list as the exploratory simulations\n",
    "short_subjs = HC_WMH[:30]\n",
    "short_subjs = np.append(short_subjs, HC_no_WMH[:30])\n",
    "short_subjs = np.append(short_subjs, MCI_no_WMH[:30])\n",
    "short_subjs = np.append(short_subjs, MCI_WMH[:30])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wmh dictionary\n",
    "wmh_dict = get_wmh_load_homogeneous(short_subjs)\n",
    "# Create a overall df and populate it with single subject results\n",
    "big_df = pd.DataFrame()\n",
    "for subj in short_subjs[2:]:\n",
    "    res_df = pd.read_csv(EXPL_DIR / f\"sub-{subj}_df_results_initial_exploration_wmh.csv\", index_col=0)\n",
    "    res_df['sub_name'] = subj\n",
    "    res_df['wmh_load'] = wmh_dict[subj]\n",
    "    big_df = pd.concat([big_df, res_df], ignore_index=True)\n",
    "# Let's work with 1-fcd and 1-phfcd so to have higher numbers = better fits\n",
    "big_df['fcd_ks'] = 1 - big_df['fcd_ks']\n",
    "big_df['phfcd_ks'] = 1 - big_df['phfcd_ks']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model fits for fc, fcd, phfcd for each subject and create one single df\n",
    "res_df_best = pd.DataFrame({'fc_pearson' : big_df.groupby([\"sub_name\"])[\"fc_pearson\"].max()}).reset_index()\n",
    "best_fcd = pd.DataFrame({'fcd_ks' : big_df.groupby([\"sub_name\"])[\"fcd_ks\"].max()}).reset_index()\n",
    "best_phfcd = pd.DataFrame({'phfcd_ks' : big_df.groupby([\"sub_name\"])[\"phfcd_ks\"].max()}).reset_index()\n",
    "res_df_best = pd.concat([res_df_best, best_fcd])\n",
    "res_df_best = pd.concat([res_df_best, best_phfcd])\n",
    "res_df_best[\"wmh_load\"] = [wmh_dict[subj] for subj in res_df_best['sub_name']]\n",
    "# Plot relationship between best model fits and wmh load \n",
    "# Here, all together, with regression\n",
    "plt.figure()\n",
    "ax1 = sns.regplot(res_df_best, y = 'fc_pearson', x = 'wmh_load', order = 2, scatter_kws={'alpha':0.3}, label = 'fc')\n",
    "ax2 = sns.regplot(res_df_best, y = 'fcd_ks', x = 'wmh_load', order = 2, scatter_kws={'alpha':0.3}, label = 'fcd')\n",
    "ax3 = sns.regplot(res_df_best, y = 'phfcd_ks', x = 'wmh_load', order = 2, scatter_kws={'alpha':0.3}, label = 'phfcd')\n",
    "ax3.set(ylabel = 'PCC / KS distance', xlabel = 'wmh load')\n",
    "plt.legend()\n",
    "plt.savefig(EXPL_FIG_DIR / \"summary_best_values_regression.png\")\n",
    "plt.close()\n",
    "# Here, separate, only with points\n",
    "fig, axs = plt.subplots(ncols= 1, nrows =3, figsize = (4, 12), sharex = True)\n",
    "axs[0].plot(res_df_best['wmh_load'], res_df_best['fc_pearson'], 'bo', alpha = 0.3)\n",
    "axs[0].set_ylabel('PCC')\n",
    "axs[0].set_title('FC')\n",
    "axs[1].plot(res_df_best['wmh_load'], res_df_best['fcd_ks'], 'go', alpha = 0.3)\n",
    "axs[1].set_ylabel('1 - KS distance')\n",
    "axs[1].set_title('FCD')\n",
    "axs[2].plot(res_df_best['wmh_load'], res_df_best['phfcd_ks'], 'ko', alpha = 0.3)\n",
    "axs[2].set_ylabel('1 - KS distance')\n",
    "axs[2].set_title('phFCD')\n",
    "fig.text(0.5, 0.04, 'Normalized WMH load', ha='center')\n",
    "plt.savefig(EXPL_FIG_DIR / \"summary_best_values_points.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This classification is based on Fazekas <=2\n",
    "hc_no_wmh_df = big_df[big_df['sub_name'].isin(HC_no_WMH)]\n",
    "hc_no_wmh_grouped = hc_no_wmh_df.drop(columns=[\"sub_name\"]).groupby([\"b\", \"w\"]).mean()\n",
    "save_plot_results(hc_no_wmh_grouped, \"hc_no_wmh_Fazekas_2\")\n",
    "\n",
    "hc_wmh_df = big_df[big_df['sub_name'].isin(HC_WMH)]\n",
    "hc_wmh_grouped = hc_wmh_df.drop(columns=[\"sub_name\"]).groupby([\"b\", \"w\"]).mean()\n",
    "save_plot_results(hc_no_wmh_grouped, \"hc_wmh_Fazekas_2\")\n",
    "\n",
    "mci_no_wmh_df = big_df[big_df['sub_name'].isin(MCI_no_WMH)]\n",
    "mci_no_wmh_grouped = mci_no_wmh_df.drop(columns=[\"sub_name\"]).groupby([\"b\", \"w\"]).mean()\n",
    "save_plot_results(mci_no_wmh_grouped, \"mci_no_wmh_Fazekas_2\")\n",
    "\n",
    "mci_wmh_df = big_df[big_df['sub_name'].isin(MCI_WMH)]\n",
    "mci_wmh_grouped = mci_wmh_df.drop(columns=[\"sub_name\"]).groupby([\"b\", \"w\"]).mean()\n",
    "save_plot_results(mci_wmh_grouped, \"mci_wmh_Fazekas_2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adnimerge = pd.read_csv(RES_DIR / \"petTOAD_dataframe.csv\")\n",
    "adnimerge[\"PTID\"] = adnimerge[\"PTID\"].str.replace(\"_\", \"\")\n",
    "\n",
    "HC_no_WMH_1q = adnimerge[\n",
    "    (adnimerge[\"PTID\"].isin(subjs))\n",
    "    & ((adnimerge[\"Group_bin_subj\"] == \"CN_no_WMH\"))\n",
    "][\"PTID\"].unique()\n",
    "\n",
    "HC_WMH_1q = adnimerge[\n",
    "    (adnimerge[\"PTID\"].isin(subjs)) & ((adnimerge[\"Group_bin_subj\"] == \"CN_WMH\"))\n",
    "][\"PTID\"].unique()\n",
    "\n",
    "MCI_no_WMH_1q = adnimerge[\n",
    "    (adnimerge[\"PTID\"].isin(subjs))\n",
    "    & ((adnimerge[\"Group_bin_subj\"] == \"MCI_no_WMH\"))\n",
    "][\"PTID\"].unique()\n",
    "\n",
    "MCI_WMH_1q = adnimerge[\n",
    "    (adnimerge[\"PTID\"].isin(subjs))\n",
    "    & ((adnimerge[\"Group_bin_subj\"] == \"MCI_WMH\"))\n",
    "][\"PTID\"].unique()\n",
    "hc_no_wmh_df = big_df[big_df['sub_name'].isin(HC_no_WMH_1q)]\n",
    "hc_no_wmh_grouped = hc_no_wmh_df.drop(columns=[\"sub_name\"]).groupby([\"b\", \"w\"]).mean()\n",
    "save_plot_results(hc_no_wmh_grouped, \"hc_no_wmh_1q\")\n",
    "\n",
    "hc_wmh_df = big_df[big_df['sub_name'].isin(HC_WMH_1q)]\n",
    "hc_wmh_grouped = hc_wmh_df.drop(columns=[\"sub_name\"]).groupby([\"b\", \"w\"]).mean()\n",
    "save_plot_results(hc_no_wmh_grouped, \"hc_wmh_1q\")\n",
    "\n",
    "mci_no_wmh_df = big_df[big_df['sub_name'].isin(MCI_no_WMH_1q)]\n",
    "mci_no_wmh_grouped = mci_no_wmh_df.drop(columns=[\"sub_name\"]).groupby([\"b\", \"w\"]).mean()\n",
    "save_plot_results(mci_no_wmh_grouped, \"mci_no_wmh_1q\")\n",
    "\n",
    "mci_wmh_df = big_df[big_df['sub_name'].isin(MCI_WMH_1q)]\n",
    "mci_wmh_grouped = mci_wmh_df.drop(columns=[\"sub_name\"]).groupby([\"b\", \"w\"]).mean()\n",
    "save_plot_results(mci_wmh_grouped, \"mci_wmh_1q\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
